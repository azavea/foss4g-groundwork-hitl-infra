{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6efb226",
   "metadata": {},
   "source": [
    "# Human-in-the-loop Machine Learning with GroundWork, Raster Vision, and STAC\n",
    "\n",
    "<img src=\"img/groundwork.png\" alt=\"GroundWork\" width=200/>\n",
    "\n",
    "<img src=\"img/raster-vision-logo.png\" alt=\"Raster Vision\" width=300/>\n",
    "\n",
    "<img src=\"img/stac.png\" alt=\"STAC\" width=300/>\n",
    "\n",
    "This notebook will walk you through a process in which you get a base model from _somewhere_, use it to create predictions, upload those predictions to the [GroundWork](https://groundwork.azavea.com/) application, correct those predictions, and use the corrections to improve your original model. Once you can get from a model to predictions to an improved model, you can repeat that process any number of times. That's the loop. You're the human. Let's rock.\n",
    "\n",
    "A note on the environment: this notebook is written to run inside a container launched by `docker/run` on `master` in the `raster-vision` repo. If you're not sure how a dependency is available, why we didn't set things up in advance, or why we're in Python 3.6, that's the reason. Additionally, the environment configured by this repository's ansible scripts makes sure that we have some specific data in a specific location. If you run this outside of that configured environment, you'll need to specificy a different path to your data.\n",
    "\n",
    "## From predictions to a GroundWork project\n",
    "\n",
    "### Step 1: Set up dependencies\n",
    "\n",
    "The `raster-vision` container has lots of things we'll need (PyTorch, the python scientific stack, a bunch of system dependencies) already available, but we'll need a few more dependencies.\n",
    "\n",
    "These additional dependencies and what we'll use them for are:\n",
    "\n",
    "- `geopandas`: to figure out which _tasks_ (more below) to put our predictions in\n",
    "- `shapely`: for transforming geojson to python data\n",
    "- `rtree`: `geopandas` needs this for spatial joins, but it's an optional dependency, so we have to say we want it\n",
    "\n",
    "Run the cell below, then restart the notebook (`0 0` or `Kernel` -> `restart`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b187832",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopandas shapely rtree seedir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702e3f3",
   "metadata": {},
   "source": [
    "After that, we'll import everything we're going to need over the rest of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import functools\n",
    "from itertools import zip_longest\n",
    "import json\n",
    "from os.path import join\n",
    "from random import random\n",
    "import time\n",
    "from uuid import uuid4\n",
    "from pprint import pformat\n",
    "from copy import deepcopy\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch, Polygon as MPolygon\n",
    "import numpy as np\n",
    "import requests\n",
    "from scipy.special import softmax\n",
    "import shapely\n",
    "from shapely.geometry import MultiPolygon, Polygon, shape\n",
    "from shapely.ops import unary_union\n",
    "import seedir as sd\n",
    "\n",
    "from rastervision.pytorch_backend.examples.utils import read_stac\n",
    "from rastervision.pipeline.file_system import unzip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334bce01",
   "metadata": {},
   "source": [
    "### Step 2: Configuration\n",
    "\n",
    "You'll configure a few values here. The goals of this configuration are to make it so that you can talk to the Raster Foundry API (the same API that powers GroundWork) from within the notebook.\n",
    "\n",
    "The values you'll configure are:\n",
    "\n",
    "- `bearer_token`: you can get this from network tools while logged in to GroundWork. This is a JSON Web Token. To see what it represents and learn more about JSON Web Tokens, you can decode it at [jwt.io](https://jwt.io/)\n",
    "- `url_base`: this value configures the scheme and host for requests to the Raster Foundry API. All of our requests will start with `app.rasterfoundry.com`\n",
    "- `source_project_id`: this value is a UUID pointing to a project template. GroundWork has two sort of high level grouping concepts -- a _project_ is a specific image that you'd like to do labeling work in, and a _campaign_ is a group of projects. Since we have predictions over an image, we want to work at the project level in this notebook.\n",
    "\n",
    "To obtain the JSON web token, open the GroundWork campaign that has been created for you called \"Jacksonville,\" open developer tools (right click in the page and choose \"inspect\"), switch to the network tab, filter to requests containing the word \"random\" in their url (type `random` into the search bar), and select the first request with the GET method. Then, inspect the request headers, right click on the authorization header, and choose \"Copy\". We'll also go through these steps in the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848782b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your token for interacting with the Raster Foundry API\n",
    "bearer_token = \"your-token-here\"\n",
    "\n",
    "# common HTTP headers shared by the requests we're going to make\n",
    "headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "\n",
    "# The base URL for the Raster Foundry API\n",
    "# This will only be different if you're working with a copy of Raster Foundry that lives somewhere else\n",
    "url_base = \"https://app.rasterfoundry.com\"\n",
    "\n",
    "# UUID of your template project\n",
    "source_project_id = \"your-project-id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e5c3b",
   "metadata": {},
   "source": [
    "Let's make sure your token is correct -- all users can make a request to `https://app.rasterfoundry.com/api/users/me` with their token to see their user information in the Raster Foundry API. If your token is correctly configured, you'll see some JSON output describing your user. If it's incorrectly configured, you'll see an exception in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_resp = requests.get(f\"{url_base}/api/users/me\", headers=headers)\n",
    "user_resp.raise_for_status()\n",
    "user_resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6875f",
   "metadata": {},
   "source": [
    "If that failed, a common way that your token can end up misconfigured is if you're using Firefox and dragged to highlight the token's value. Because the header value is quite long, Firefox helpfully (citation needed) truncates it, and you end up with a unicode ellipsis (`...`) in the middle of the value. To correct this, instead right click the header's value and choose `copy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf5634",
   "metadata": {},
   "source": [
    "### Step 3: Create a copy of your template project\n",
    "\n",
    "The workflow we'll use in this workshop is that each iteration of the human-in-the-loop workflow will create a new project based on the template that we configured above. The steps to copy a project are:\n",
    "\n",
    "- fetch the existing project\n",
    "- create a new JSON document like from fields in that project\n",
    "- POST that new project to the Raster Foundry API\n",
    "- fetch all the tasks in the existing project\n",
    "- add them to the new project by changing their project reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f54319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the source project\n",
    "@functools.lru_cache(None)\n",
    "def fetch_project(project_id):\n",
    "    return requests.get(join(url_base, \"api\", \"annotation-projects\", \n",
    "                             project_id), headers=headers).json()\n",
    "\n",
    "# create a new JSON document from the source project\n",
    "def make_project_clone_json(source_project, iteration_number=0):\n",
    "    return {\n",
    "        # the name is just the source project name with a \"_HITL\" suffix\n",
    "        \"name\": f\"\"\"{source_project[\"name\"]} {iteration_number}\"\"\",\n",
    "        \"projectType\": source_project[\"projectType\"],\n",
    "        \"taskSizePixels\": 512,\n",
    "        \"aoi\": source_project[\"aoi\"],\n",
    "        \"labelersTeamId\": source_project[\"labelersTeamId\"],\n",
    "        \"validatorsTeamId\": source_project[\"validatorsTeamId\"],\n",
    "        \"projectId\": None,\n",
    "        \"campaignId\": source_project[\"campaignId\"],\n",
    "        \"status\": source_project[\"status\"],\n",
    "        \"tileLayers\": source_project[\"tileLayers\"],\n",
    "        \"labelClassGroups\": []\n",
    "    }\n",
    "\n",
    "# post the project copy to the Raster Foundry API\n",
    "def post_project(project_json):\n",
    "    post_hitl_url = join(url_base, \"api\",\"annotation-projects\")\n",
    "    post_hitl = requests.post(post_hitl_url, headers=headers, json=project_json)\n",
    "    post_hitl.raise_for_status()\n",
    "    return post_hitl.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19376f",
   "metadata": {},
   "source": [
    "So we can get the source project by bundling that workflow up with `project_id` and `iteration_number` parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5da1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_project(project_id, iteration_number):\n",
    "    source_project = fetch_project(project_id)\n",
    "    new_project = make_project_clone_json(source_project, iteration_number)\n",
    "    return post_project(new_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6b20e",
   "metadata": {},
   "source": [
    "We can then make our first copy of the template project like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1edf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitl_project = clone_project(source_project_id, 1)\n",
    "f\"\"\"https://groundwork.azavea.com/app/campaign/{hitl_project[\"campaignId\"]}/overview?p=0&f=all\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5919ba",
   "metadata": {},
   "source": [
    "You can visit that URL in the GroundWork app and select the project you just created to see that we've created a copy of the project that has the same imagery tile layer, but it doesn't appear to have any tasks.\n",
    "\n",
    "#### Uploading tasks\n",
    "\n",
    "GroundWork breaks labeling work into more manageable pieces called _tasks_. A task is a specific window within a larger image. If you look at the overview for the source project, each little box over the imagery is a task.\n",
    "\n",
    "To fill in tasks, we'll need to:\n",
    "\n",
    "* grab all of the tasks from the source project\n",
    "* POST them to the new project\n",
    "\n",
    "Since the number of tasks in the source project can be huge, we'll work in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all of the tasks from the source project\n",
    "def fetch_tasks(annotation_project_id, url_base):\n",
    "    template_project_tasks_url = join(url_base,\"api/annotation-projects/\", annotation_project_id, \"tasks\")\n",
    "    tasks = requests.get(template_project_tasks_url, headers=headers).json()\n",
    "    has_next = tasks[\"hasNext\"]\n",
    "    next_page = 1\n",
    "    while has_next:\n",
    "        new_tasks_url = f\"{template_project_tasks_url}?page={next_page}\"\n",
    "        next_tasks = requests.get(new_tasks_url, headers=headers).json()\n",
    "        tasks[\"features\"] += next_tasks[\"features\"]\n",
    "        has_next = next_tasks[\"hasNext\"]\n",
    "        next_page += 1\n",
    "    return tasks\n",
    "\n",
    "# break all tasks into manageable chunks\n",
    "# modified from https://docs.python.org/3/library/itertools.html#itertools-recipes\n",
    "def grouper(iterable, n):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    x = zip_longest(*args)\n",
    "    # workaround to remove the fill values in the chunks\n",
    "    return [[ii for ii in i if ii is not None] for i in x]\n",
    "\n",
    "# POST the tasks to the new project in groups\n",
    "def copy_tasks_to_project(source_tasks, project_id):\n",
    "    tasks_post_url = join(url_base, \"api\", \"annotation-projects\", project_id, \"tasks\")\n",
    "    chunks = grouper(source_tasks['features'], 1250)\n",
    "    out = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "    for chunk in chunks:\n",
    "        chunk_tasks = {\"features\": [], \"type\": \"FeatureCollection\"}\n",
    "        for task in chunk:\n",
    "            # set the status to unlabeled, no matter what it was before\n",
    "            task[\"properties\"][\"status\"] = \"UNLABELED\"\n",
    "            # set the annotationProjectId to \n",
    "            task[\"properties\"][\"annotationProjectId\"] = project_id\n",
    "            chunk_tasks[\"features\"] += [task]\n",
    "    \n",
    "        chunk_tasks_response = requests.post(tasks_post_url, headers=headers, json=chunk_tasks)\n",
    "        # make sure this post request doesn't fail silently\n",
    "        chunk_tasks_response.raise_for_status()\n",
    "        out[\"features\"] += chunk_tasks_response.json()[\"features\"]\n",
    "    return out\n",
    "\n",
    "# One-shot to grab all the tasks and do the copy\n",
    "def clone_tasks(from_project_id, to_project_id):\n",
    "    source_tasks = fetch_tasks(source_project_id, url_base)\n",
    "    return copy_tasks_to_project(source_tasks, to_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitl_project_tasks = clone_tasks(source_project_id, hitl_project[\"id\"])\n",
    "len(hitl_project_tasks[\"features\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8770a6",
   "metadata": {},
   "source": [
    "### Step 4: upload labels\n",
    "\n",
    "Now that we have a project and tasks, we can upload our labels. To upload the labels, we'll need to complete three steps:\n",
    "\n",
    "* associate each predicted label with a label class\n",
    "* associate each predicted label with a task\n",
    "* POST all the labels to GroundWork\n",
    "\n",
    "Each label has to be associated with a task within a project and with a label class. GroundWork associates labels with classes via UUIDs, while Raster Vision only speaks string names, so we'll need to make sure we can translate between the names and IDs. Fortunately, we can get that translation from the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dict to map from label name (from Raster Vision) to label class id (GroundWork / Raster Foundry)\n",
    "def get_class_map(project):\n",
    "    campaign_id = project['campaignId']\n",
    "    get_label_class_url = join(url_base, \"api\", \"campaigns\", campaign_id, \"label-class-groups\")\n",
    "    label_class_summary = requests.get(get_label_class_url, headers=headers).json()\n",
    "    return {d['name']: d['id'] for d in label_class_summary[0]['labelClasses']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4681f8ad",
   "metadata": {},
   "source": [
    "Joining labels to tasks is slightly more complex. Our labels in this case are chip classification labels. Those chips won't align perfectly with the task grid that we created. However, both the tasks and the chips happen to be square, so we know that if the centroid of a label is located within a task, that's the most appropriate task for the label. We can do this kind of join with geopandas. We'll also need to track the predictions' original geometries though, so we'll return that in a separate map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_tasks(predictions_feature_collection, tasks_feature_collection):\n",
    "    geom_mapping = {}\n",
    "    tasks_df = gpd.GeoDataFrame.from_features(tasks_feature_collection[\"features\"], crs=\"epsg:4326\")\n",
    "    copied = deepcopy(predictions_feature_collection)\n",
    "    for f in copied[\"features\"]:\n",
    "        f[\"properties\"][\"score\"] = np.max(softmax(f[\"properties\"][\"scores\"]))\n",
    "        geom = shape(f[\"geometry\"])\n",
    "        ad_hoc_id = str(uuid4())\n",
    "        geom_mapping[ad_hoc_id] = geom\n",
    "        f[\"properties\"][\"ad-hoc-id\"] = ad_hoc_id\n",
    "        # find the centroids which we will use for easier joining to task grid\n",
    "        f[\"geometry\"] = geom.centroid\n",
    "    return {\"original_geometries\": geom_mapping,\n",
    "            \"joined\": sjoin(\n",
    "                tasks_df,\n",
    "                gpd.GeoDataFrame.from_features(copied['features'], crs='EPSG:4326'),\n",
    "                how=\"left\"\n",
    "            )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37557da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_output_uri = \"../base-predictions.json\"\n",
    "\n",
    "with open(rv_output_uri, \"r\") as inf:\n",
    "    predictions_feature_collection = json.load(inf)\n",
    "\n",
    "labels_with_task_ids = associate_tasks(predictions_feature_collection, hitl_project_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae53c3",
   "metadata": {},
   "source": [
    "Finally, we can post these predictions to GroundWork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the json needed to post labels from each row in the labels with task ID table\n",
    "def features_to_label_post_body(group, geom_mapping, class_map):\n",
    "    def feature_to_label(r):\n",
    "        try:\n",
    "            invert = r[\"class_name\"] == \"background\"\n",
    "            return { \"type\": \"Feature\",\n",
    "              \"properties\": {\n",
    "                \"annotationLabelClasses\": [class_map[\"boat\"]],\n",
    "                \"score\": r[\"score\"] if not invert else 1 - r[\"score\"]\n",
    "              },\n",
    "              \"geometry\": shapely.geometry.mapping(geom_mapping[r[\"ad-hoc-id\"]]),\n",
    "             \"id\": r[\"id\"]\n",
    "            }\n",
    "        except:\n",
    "            print(\"Failing row:\")\n",
    "            print(r)\n",
    "            raise\n",
    "\n",
    "    return {\n",
    "      \"type\":\"FeatureCollection\",\n",
    "      \"features\": [feature_to_label(r) for _, r in group.iterrows() if not gpd.pd.isna(r['class_name'])],\n",
    "        \"nextStatus\":\"LABELED\"\n",
    "    }\n",
    "\n",
    "def upload_labels(project_id, joined, original_geometries, class_map):\n",
    "    for task_id, task_labels in joined.groupby(\"id\"):\n",
    "        label_upload_body = features_to_label_post_body(task_labels, original_geometries, class_map)\n",
    "        label_upload_url = join(url_base, \"api\", \"annotation-projects\", project_id, \"tasks\", task_id, \"labels\")\n",
    "        # we use a PUT here so that if we fail in the middle, we can try again and replace the labels\n",
    "        label_upload_response = requests.put(label_upload_url, headers=headers, json=label_upload_body)\n",
    "        # make sure this post request doesn't fail silently\n",
    "        label_upload_response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = get_class_map(hitl_project)\n",
    "upload_labels(hitl_project[\"id\"], class_map=class_map, **labels_with_task_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f68ad",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "The above steps are all separated out, but we can instead write a single function that runs through the entire workflow like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rv_label_project(source_project_id, iteration_number, rv_output_uri):\n",
    "    hitl_project = clone_project(source_project_id, iteration_number)\n",
    "    hitl_project_tasks = clone_tasks(source_project_id, hitl_project[\"id\"])\n",
    "    \n",
    "    with open(rv_output_uri, \"r\") as inf:\n",
    "        predictions_feature_collection = json.load(inf)\n",
    "    labels_with_task_ids = associate_tasks(predictions_feature_collection, hitl_project_tasks)\n",
    "    class_map = get_class_map(hitl_project)\n",
    "    upload_labels(hitl_project[\"id\"], class_map=class_map, **labels_with_task_ids)\n",
    "    return hitl_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can skip this for now unless you want to create another project\n",
    "create_rv_label_project(source_project_id, 1, rv_output_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ab8b0",
   "metadata": {},
   "source": [
    "We'll return to this step later when we run through the loop again.\n",
    "\n",
    "## From GroundWork to new training data\n",
    "\n",
    "Before, we set a task status of `UNLABELED` when we created tasks, then `LABELED` when we uploaded labels to them. There's a more advanced status, `VALIDATED`, that indicates that a human has reviewed some labels and signed off on them. We can use the validation process in GroundWork to correct the predictions produced by Raster Vision.\n",
    "\n",
    "The validation workflow uses GroundWork. After you're done with that, come back here.\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "Done validating? Great. Let's create some new training data.\n",
    "\n",
    "To do that, we'll create a STAC export. STAC is short for the [spatio-temporal asset catalog specification](https://github.com/radiantearth/stac-spec), an open, extensible standard for describing geospatial data. GroundWork knows how to export, and Raster Vision knows how to train models from, STAC catalogs implementing the [label extension](https://github.com/stac-extensions/label). We can create a new export using the `/stac` endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validated_stac_export(campaign_id):\n",
    "    export_post = {\n",
    "        \"name\": \"GW HITL Workshop export\",\n",
    "        \"license\": {\"license\": \"proprietary\"},\n",
    "        \"taskStatuses\": [\"VALIDATED\"],\n",
    "        \"exportAssetType\": None,\n",
    "        \"campaignId\": campaign_id\n",
    "    }\n",
    "    resp = requests.post(f\"{url_base}/api/stac\", headers=headers, json=export_post)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cf434",
   "metadata": {},
   "source": [
    "We can wait for the export to complete within the notebook by checking its status and sleeping -- exports don't take very long so we won't have to sleep too often:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8710675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_export(export):\n",
    "    export = requests.get(f\"\"\"{url_base}/api/stac/{export[\"id\"]}\"\"\", headers=headers).json()\n",
    "    if export[\"exportStatus\"] != \"EXPORTED\":\n",
    "        time.sleep(10)\n",
    "        return wait_for_export(export)\n",
    "    return export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b086a7",
   "metadata": {},
   "source": [
    "Similarly to before, we can create a single function that creates and waits for the export, then prints the download URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_campaign(campaign_id):\n",
    "    export = create_validated_stac_export(campaign_id)\n",
    "    completed = wait_for_export(export)\n",
    "    return completed[\"downloadUrl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb024b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_id = hitl_project[\"campaignId\"]\n",
    "download_url = export_campaign(campaign_id)\n",
    "download_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca0266",
   "metadata": {},
   "source": [
    "We can download and unzip that export easily with bash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822cdaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_num = 1\n",
    "\n",
    "!mkdir -p export-data/iter-{iter_num}\n",
    "!wget -O export-data/iter-{iter_num}/stac-export.zip \"{download_url}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2280852-aced-4287-8677-e27ab16bf6d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inspect the STAC export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899521b-2d5d-4d06-9930-be1b260c373e",
   "metadata": {},
   "source": [
    "Let's see what's in the export and how Raster Vision is going to turn this into training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00317326-e999-4244-b135-d4c4b03c8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the downloaded location of the zip containing the STAC export we created before\n",
    "stac_export_uri = f\"./export-data/iter-{iter_num}/stac-export.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39c1d6-4ad5-4739-9ad9-7a39f2cdc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_zipfile(path):\n",
    "    with TemporaryDirectory() as tmp_dir:\n",
    "        unzip(path, target_dir=tmp_dir)\n",
    "        s = sd.seedir(path=tmp_dir, style='lines', indent=4, first='files', printout=False)\n",
    "        root = s.split('\\n')[0]\n",
    "        s = s.replace(root, f'{path}/')\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1f860-0090-4fe2-8a55-a4ad2803b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_zipfile(stac_export_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40a4cc-2464-4ec7-8c5e-f911510c1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_parsed_stac(project_infos):\n",
    "    project_infos = deepcopy(project_infos)\n",
    "    for info in project_infos:\n",
    "        g = shape(info['aoi_geometry'])\n",
    "        info['aoi_geometry']['coordinates'] = '[[...]]'\n",
    "        info['image_bbox'] = info['image_bbox'].bounds\n",
    "        info['label_bbox'] = info['label_bbox'].bounds\n",
    "    print(pformat(project_infos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545279e6-8053-40b4-a2ac-62788a4338e0",
   "metadata": {},
   "source": [
    "`read_stac()` is a util function that Raster Vision uses to extract labels and other data from the STAC export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ee827-8f19-46b0-9658-25d4b1428f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_infos = read_stac(stac_export_uri, f'./tmp/inspect-export-{iter_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827cf5eb-1d3b-4401-8e9b-38d9293c661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_parsed_stac(project_infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0841d5-8d22-47d9-b6e2-f04559ae8d42",
   "metadata": {},
   "source": [
    "If you want a closer look at the export contents, you can unzip it and then explore it using the notebook server's file browser. Start with `README.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc986872",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -d export-data/iter-{iter_num}/ export-data/iter-{iter_num}/stac-export.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da3eec-4017-4bb3-b652-148a0f2c130e",
   "metadata": {},
   "source": [
    "### What do the training labels look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec2c44-f5fe-4b2f-9565-1681ee56fb27",
   "metadata": {},
   "source": [
    "As a sanity check, we can visualize the labels that we will actually be feeding into Raster Vision for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aac304-eff8-4c92-9a31-a9fee4ab1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geojson_to_shape(path):\n",
    "    with open(path, 'r') as f:\n",
    "        features = json.load(f)['features']\n",
    "    polygons = [shape(f['geometry']) for f in features]\n",
    "    polygons = unary_union(polygons)\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333bfac-0f55-4eef-9fac-a4e2b695ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_labels_combined(infos):\n",
    "    fig = plt.figure(figsize=(12, 18))\n",
    "    ax = plt.gca()\n",
    "    extent = Polygon.from_bounds(*unary_union([info['label_bbox'] for info in infos]).bounds)\n",
    "    ax.add_patch(MPolygon(np.array(extent.exterior), fill=None, hatch='/', alpha=.5))\n",
    "    for info in infos:\n",
    "        aoi_polygons = shape(info['aoi_geometry'])\n",
    "        if isinstance(aoi_polygons, Polygon):\n",
    "            aoi_polygons = MultiPolygon([aoi_polygons])\n",
    "        label_polygons = geojson_to_shape(info['label_uri'])\n",
    "        if isinstance(label_polygons, Polygon):\n",
    "            label_polygons = MultiPolygon([label_polygons])\n",
    "        for p in aoi_polygons:\n",
    "            ax.add_patch(MPolygon(np.array(p.exterior), fc='white', ec='#777'))\n",
    "        for p in label_polygons:\n",
    "            ax.add_patch(MPolygon(np.array(p.exterior), fc='r', ec='r'))\n",
    "    plt.axis('off')\n",
    "    plt.autoscale()\n",
    "    legend_patches = [\n",
    "        Patch(fc='w', ec='k', hatch='/', alpha=.5, label='Unlabeled region'),\n",
    "        Patch(fc='w', ec='#777', alpha=1, label='Labeled region'),\n",
    "        Patch(color='r', alpha=1, label='Boat'),\n",
    "    ]\n",
    "    plt.legend(handles=legend_patches, loc='upper center', bbox_to_anchor=(.5, .985), fontsize='xx-large', frameon=False, ncol=3)\n",
    "    fig.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435887d5-d72b-4f52-8b31-f299fe8dca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_labels_combined(project_infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b497d4-a075-454d-b24e-861e9178a1e4",
   "metadata": {},
   "source": [
    "To get training chips, Raster Vision will randomly sample 300x300 (pixels) chips from the labeled regions only. If a chip happens to intersect with any boat polygons, it will be assigned the class `\"boat\"`, otherwise it will be considered a `\"background\"` chip. Raster Vision will train a classification model that classifies chips into one of two classes: `\"boat\"` and `\"background\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48ed64",
   "metadata": {},
   "source": [
    "## From new training data to new predictions\n",
    "\n",
    "Now that we have new training data, we can train a new model based on our original model. We can load our original model from a file containing its weights. Again, this step starts with some configuration. We'll configure a few values that control how the Raster Vision training works:\n",
    "\n",
    "- `MODEL_INIT_WEIGHTS_PATH`: where the pre-trained model weights live\n",
    "- `OUTPUT_ROOT`: the directory that will serve as the base for next training runs\n",
    "- `RV_CONFIG_FILE`: a python module containing a `get_config` function that returns a Raster Vision experiment config\n",
    "- `stac_export_uri`: the downloaded location of the zip containing the STAC export we created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_INIT_WEIGHTS_PATH = \"../init_weights.pth\"\n",
    "OUTPUT_ROOT = \"./output\"\n",
    "RV_CONFIG_FILE = \"./active_learning.py\"\n",
    "\n",
    "output_dir = f\"{OUTPUT_ROOT}/iter_{iter_num}\"\n",
    "stac_export_uri = f\"./export-data/iter-{iter_num}/stac-export.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a1976",
   "metadata": {},
   "source": [
    "With those values configured, we can re-train our original model with the new training data we just exported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb8611-8c35-419a-9fa2-639fdb200983",
   "metadata": {},
   "source": [
    "### Training and making predictions with Raster Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce849397-0bd9-4f96-acac-58df0ecd1a8a",
   "metadata": {},
   "source": [
    "Raster Vision allows setting up a reusable pipline for a typical machine learning workflow. The full pipeline looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0a6ad-7f6e-415e-b0de-ec7d79a8fdd3",
   "metadata": {},
   "source": [
    "<img src=\"img/rv_blog_pipeline.png\" alt=\"RV pipelien\" style=\"width: 800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a132825-7411-48ae-ae93-569eeb7c934b",
   "metadata": {},
   "source": [
    "Here, we will only be making use of the `train` and `predict` stages. The pipeline is highly configurable, but most of the configuration has already been taken care of and is defined in the file `RV_CONFIG_FILE`.\n",
    "\n",
    "We can run Raster Vision using the command below. Its components can be understood as:\n",
    "- `run inprocess`: runs Raster Vision locally with the configured commands and arguments\n",
    "- `\"{RV_CONFIG_FILE}\"`: Raster Vision will run the `get_config()` function defined in this file to get the pipeline configuration.\n",
    "- `train predict`: runs only the `train` and `predict` stages\n",
    "- `-a <key> <value>`: these options get passed to the `get_config()` function in `RV_CONFIG_FILE` as keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rastervision run inprocess \"{RV_CONFIG_FILE}\" \\\n",
    "    train predict bundle \\\n",
    "    -a output_dir \"{output_dir}\" \\\n",
    "    -a stac_export_uri \"{stac_export_uri}\" \\\n",
    "    -a init_weights \"{MODEL_INIT_WEIGHTS_PATH}\" \\\n",
    "    -a num_epochs \"3\" \\\n",
    "    -a chips_per_scene \"100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291dc91",
   "metadata": {},
   "source": [
    "### Inspect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09676014",
   "metadata": {},
   "source": [
    "Now we have some new predictions -- we can see the distribution of predicted scores for whether a chip contains a boat like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44153799",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_dir}/predict/val-0.json\", \"r\") as f:\n",
    "    preds = json.load(f)\n",
    "\n",
    "scores_boat = np.array([softmax(f['properties']['scores'])[1] for f in preds['features']])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.hist(scores_boat, bins=30, alpha=0.5, label='boat')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd545ab6",
   "metadata": {},
   "source": [
    "What do we do with those predictions? Well, we have a nice little workflow for getting them into GroundWork, and then to correct them and turn them into new training data. A shorter version of the workflow can be seen below --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b84cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new project\n",
    "\n",
    "# increment this value each time you create a new project\n",
    "iter_num = 2\n",
    "\n",
    "rv_output_uri = f\"./output/iter_{iter_num - 1}/predict/val-0.json\"\n",
    "\n",
    "next_project = create_rv_label_project(source_project_id, iter_num, rv_output_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bb066",
   "metadata": {},
   "source": [
    "Then go validate some labels, then create a new export:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c718960",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_training_url = export_campaign(next_project[\"campaignId\"])\n",
    "next_training_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73fb1d",
   "metadata": {},
   "source": [
    "Finally, download the new training data, and re-run training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa33f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"{OUTPUT_ROOT}/iter_{iter_num}\"\n",
    "stac_export_uri = f\"./export-data/iter-{iter_num}/stac-export.zip\"\n",
    "\n",
    "!mkdir -p export-data/iter-{iter_num}\n",
    "!wget -O export-data/iter-{iter_num}/stac-export.zip \"{next_training_url}\"\n",
    "!rastervision run inprocess \"{RV_CONFIG_FILE}\" \\\n",
    "    train predict bundle \\\n",
    "    -a output_dir \"{output_dir}\" \\\n",
    "    -a num_epochs \"3\" \\\n",
    "    -a chips_per_scene \"100\" \\\n",
    "    -a stac_export_uri \"{stac_export_uri}\" \\\n",
    "    -a init_weights \"{MODEL_INIT_WEIGHTS_PATH}\"\n",
    "\n",
    "!rastervision predict \\\n",
    "  {output_dir}/bundle/model-bundle.zip \\\n",
    "  ../jacksonville.sub.tif \\\n",
    "  {output_dir}/predict/val-0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d874c13",
   "metadata": {},
   "source": [
    "You can re-run the above three cells, incrementing `iter_num` each time, with the validation step in the middle as many times as you want to improve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
