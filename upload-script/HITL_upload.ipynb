{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from random import random\n",
    "from os.path import join\n",
    "from itertools import zip_longest\n",
    "from copy import deepcopy\n",
    "\n",
    "import shapely\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from scipy.special import softmax\n",
    "from geopandas.tools import sjoin\n",
    "from shapely.geometry import MultiPolygon, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e5cde8",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437590f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bearer_token = \"\"\n",
    "\n",
    "# url_base = \"\"\n",
    "\n",
    "# source_project_id = \"\"\n",
    "\n",
    "# rv_output_uri = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bcd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {bearer_token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf37451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the source project\n",
    "source_project = requests.get(join(url_base, \"api\", \"annotation-projects\", \n",
    "                                   source_project_id), headers=headers).json()\n",
    "\n",
    "# Construct a JSON for the HITL project which will have the same task grid and label\n",
    "# classes as the source project\n",
    "hitl_project_post_body = {\n",
    "    # the name is just the source project name with a \"_HITL\" suffix\n",
    "    \"name\": source_project[\"name\"] + \"_HITL\",\n",
    "    \"projectType\": source_project[\"projectType\"],\n",
    "    \"taskSizePixels\": 512,\n",
    "    \"aoi\": source_project[\"aoi\"],\n",
    "    \"labelersTeamId\": source_project[\"labelersTeamId\"],\n",
    "    \"validatorsTeamId\": source_project[\"validatorsTeamId\"],\n",
    "    \"projectId\": source_project[\"projectId\"],\n",
    "    \"campaignId\": source_project[\"campaignId\"],\n",
    "    \"status\": source_project[\"status\"],\n",
    "    \"tileLayers\": source_project[\"tileLayers\"],\n",
    "    \"labelClassGroups\": []\n",
    "}\n",
    "\n",
    "\n",
    "post_hitl_url = join(url_base, \"api\",\"annotation-projects\")\n",
    "post_hitl = requests.post(post_hitl_url, headers=headers, json=hitl_project_post_body)\n",
    "hitl_project = post_hitl.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0515e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dict to map from label name (from rv) to annotation ID\n",
    "hitl_campaign_id = hitl_project['campaignId']\n",
    "get_label_class_url = join(url_base, \"api\", \"campaigns\", hitl_campaign_id, \"label-class-groups\")\n",
    "label_class_summary = requests.get(get_label_class_url, headers=headers).json()\n",
    "label_name_to_annotation_id = {d['name']: d['id'] for d in label_class_summary[0]['labelClasses']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all tasks in source project\n",
    "def fetch_tasks(annotation_project_id, url_base, headers):\n",
    "    template_project_tasks_url = join(url_base,\"api/annotation-projects/\", annotation_project_id, \"tasks\")\n",
    "    tasks = requests.get(template_project_tasks_url, headers=headers).json()\n",
    "    has_next = tasks[\"hasNext\"]\n",
    "    next_page = 1\n",
    "    while has_next:\n",
    "        new_tasks_url = f\"{template_project_tasks_url}?page={next_page}\"\n",
    "        next_tasks = requests.get(new_tasks_url, headers=headers).json()\n",
    "        tasks[\"features\"] += next_tasks[\"features\"]\n",
    "        has_next = next_tasks[\"hasNext\"]\n",
    "        next_page += 1\n",
    "    return tasks\n",
    "\n",
    "source_project_tasks = fetch_tasks(source_project_id, url_base, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb813440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate the tasks for the new project\n",
    "hitl_project_tasks = deepcopy(source_project_tasks)\n",
    "hitl_project_tasks[\"features\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate the source project's task grid in the HITL project\n",
    "\n",
    "# break all tasks into manageable chunks\n",
    "# modified from https://docs.python.org/3/library/itertools.html#itertools-recipes\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    x = zip_longest(*args)\n",
    "    # workaround to remove the fill values in the chunks\n",
    "    return [[ii for ii in i if ii != fillvalue] for i in x]\n",
    "\n",
    "# 1250 is the max number of tasks that GW can handle in \n",
    "chunks = grouper(source_project_tasks['features'], 1250)\n",
    "\n",
    "for chunk in chunks:\n",
    "    chunk_tasks = deepcopy(hitl_project_tasks)\n",
    "    chunk_tasks['count'] = len(chunk)\n",
    "    chunk_tasks['features'] = []\n",
    "    for task in chunk:\n",
    "        task[\"properties\"][\"status\"] = \"UNLABELED\"\n",
    "        task[\"properties\"][\"annotationProjectId\"] = hitl_project[\"id\"]\n",
    "        chunk_tasks[\"features\"] += [task]\n",
    "    \n",
    "    tasks_post_url = join(url_base, \"api\", \"annotation-projects\", hitl_project[\"id\"], \"tasks\")\n",
    "    chunk_tasks_response = requests.post(tasks_post_url, headers=headers, json=chunk_tasks)\n",
    "    # make sure this post request doesn't fail silently\n",
    "    chunk_tasks_response.raise_for_status()\n",
    "    hitl_project_tasks[\"features\"] += chunk_tasks_response.json()[\"features\"]\n",
    "\n",
    "hitl_gdf = gpd.GeoDataFrame.from_features(hitl_project_tasks[\"features\"], crs=\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0921d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in rv output\n",
    "with open(\"example_rv_output.json\", \"r\") as f:\n",
    "    rv_json = json.load(f)\n",
    "\n",
    "for f in rv_json['features']:\n",
    "    # convert rv scores to probabilities\n",
    "    f['properties']['score'] = np.max(softmax(f['properties']['scores']))\n",
    "    # find the centroids which we will use for easier joining to task grid\n",
    "    f['geometry'] = shape(f['geometry']).centroid\n",
    "\n",
    "rv_centroids = gpd.GeoDataFrame.from_features(rv_json['features'], crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the corresponding task for each label\n",
    "labels_with_task_ids = sjoin(hitl_gdf, rv_centroids, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff607f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the annotation project id for the HITL project\n",
    "hitl_annotation_project_id = hitl_project['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the json needed to post labels from each row in the labels with task ID table\n",
    "def features_to_label_post_body(group):\n",
    "    def feature_to_label(r):\n",
    "        return { \"type\": \"Feature\",\n",
    "          \"properties\": {\n",
    "            \"annotationLabelClasses\": [label_name_to_annotation_id[r['class_name']]],\n",
    "            \"score\": r['score']\n",
    "          },\n",
    "          \"geometry\": shapely.geometry.mapping(MultiPolygon([r['geometry']])),\n",
    "         \"id\": r[\"id\"]\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "      \"type\":\"FeatureCollection\",\n",
    "      \"features\": [feature_to_label(r) for _, r in group.iterrows()],\n",
    "        \"nextStatus\":\"LABELED\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload each label \n",
    "for task_id, task_labels in labels_with_task_ids.groupby('id'):\n",
    "    label_upload_body = features_to_label_post_body(task_labels)\n",
    "    label_upload_url = join(url_base, \"api\", \"annotation-projects\", hitl_annotation_project_id, \"tasks\", task_id, \"labels\")\n",
    "    label_upload_response = requests.put(label_upload_url, headers=headers, json=label_upload_body)\n",
    "    # make sure this post request doesn't fail silently\n",
    "    label_upload_response.raise_for_status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
